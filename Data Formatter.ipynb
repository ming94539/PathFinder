{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. Abbreviation - B.A. B.S. - after my punctuation remover, it becomes B A B S. Making it miss stuff\\n2. Tokenization - Miss key words with two or more words like \"React Native\"\\n3. Double spaces - not completely sure yet but I think it\\'s from the punctuation remover, but \\nthe regex that removes multiple consecutive spaces can deal with that\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Problems Encountered\n",
    "'''\n",
    "1. Abbreviation - B.A. B.S. - after my punctuation remover, it becomes B A B S. Making it miss stuff\n",
    "2. Tokenization - Miss key words with two or more words like \"React Native\"\n",
    "3. Double spaces - not completely sure yet but I think it's from the punctuation remover, but \n",
    "the regex that removes multiple consecutive spaces can deal with that\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate Job Posts, put them all in a list, with each element a job post\n",
    "#Preprocessing like removing punctuations, lowercase everything\n",
    "def preprocessing(jobs_file):\n",
    "    jobsFile = open(jobs_file)\n",
    "    jobslines = jobsFile.readlines()\n",
    "    origPosts = []\n",
    "    jobPosts = []\n",
    "    post = \"\"\n",
    "    origPost = \"\"\n",
    "    firstOne = True\n",
    "    for l in range(len(jobslines)):\n",
    "        if jobslines[l] == \"BREAK\\n\":\n",
    "            if firstOne:\n",
    "                firstOne = False\n",
    "            else:\n",
    "                jobPosts.append(post)\n",
    "                origPosts.append(origPost)\n",
    "                post = \"\"\n",
    "                origPost = \"\"\n",
    "            continue\n",
    "        origPost += jobslines[l]\n",
    "        if l == len(jobslines)-1:\n",
    "            jobPosts.append(post)\n",
    "            origPosts.append(origPost)\n",
    "       # post += jobslines[l].replaceAll(\"[\\\\p{Punct}&&[^.]]\", \"\").lower();\n",
    "        post+= re.sub(r'[^\\w\\s]', ' ', jobslines[l].lower())\n",
    "\n",
    "    print('----')\n",
    "    for p in range(len(jobPosts)):\n",
    "        jobPosts[p]= re.sub(' +', ' ', jobPosts[p].replace('\\n',' ')) #remove unnecessary double/triple white space\n",
    "    # for p in range(len(jobPosts)):\n",
    "    #     jobPosts[p] = word_tokenize(jobPosts[p])\n",
    "    return origPosts, jobPosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kuaishou is the leading short video and photo sharing App in China where our mission is to provide users with a personal space to share moments from their lives. With over 700 million audience and more than 200 million active daily users, Kwai provides an almost limitless look at everyday slices of life that unfolds in real time. Viewers can explore a rich array of glimpses into fitness, homes, cooking, health and wellness, fashion, and other interests.\n",
      "\n",
      "\n",
      "Kuaishou is a user-oriented, technology-driven company which uses cutting edge machine learning techniques for instantly curated presentations and develops new AI algorithms and technologies to solve challenging industrial problems.\n",
      "\n",
      "\n",
      "You may visit https://usrdc.kuaishou.com/ to learn more about us.\n",
      "\n",
      "\n",
      "About the Position:\n",
      "\n",
      "We are an applied research and engineering team responsible for developing advanced AI technologies and hardware platforms for efficient inferences on cloud servers or edge devices across Kuaishou products. We are looking for Deep Learning Software Interns at our Palo Alto Office to develop exciting technologies for Kuaishou’s next generation products. \n",
      "\n",
      "\n",
      "JOB RESPONSIBILITIES:\n",
      "\n",
      "• Develop and prototype new deep learning models and training algorithms for speech recognition, computer vision, and natural language processing\n",
      "\n",
      "• Train deep learning models on computing clusters to perform audio and visual recognition tasks\n",
      "\n",
      "• Analyze and optimize deep neural algorithms, and associated pre-/post-processing code, including not limit to model compresion, quantization, and acceleration\n",
      "\n",
      "• Develop fixed-point implementation of common operators in Tensorflow or PyTorch \n",
      "\n",
      "MINIMUM QUALIFICATIONS\n",
      "\n",
      "• Master or PhD in Computer Engineering, Computer Science and Electrical Engineering or other related fields \n",
      "\n",
      "• Familiar with basic deep learning concepts, including convolutional neural network and recurrent neural network \n",
      "\n",
      "• Proficiency in at least one major machine learning framework, such as Tensorflow and PyTorch\n",
      "\n",
      "• Hands-on programming and debugging experience in C/C++ or Python\n",
      "\n",
      "• Creativity and curiosity for solving highly complex problems\n",
      "\n",
      "• Excellent communication and collaboration skills\n",
      "\n",
      "\n",
      "PREFERRED QUALIFICATIONS\n",
      "\n",
      "• Solid mathematical background, especially in optimization theory, random process, and linear algebra\n",
      "\n",
      "• Knowledge in neural network optimization techniques, such as quantization, compression, pruning and layer fusion\n",
      "\n",
      "• Basic understanding of computer architecture and computing platforms, such as CPU, GPU, FPGA or DSP\n",
      "\n",
      "• Familiar with neural network, image processing and video compression\n",
      "\n",
      "Applicant rank\n",
      "Top 50% of 159 applicants\n",
      "Contact the job poster\n",
      "Job poster profile\n",
      "Meiqi Wu\n",
      "快手 - HR（招聘）\n",
      "\n",
      "Send InMail\n",
      "Job Details\n",
      "Seniority Level\n",
      "Internship\n",
      "\n",
      "Industry\n",
      "Internet\n",
      "Employment Type\n",
      "Internship\n",
      "\n",
      "Job Functions\n",
      "Science  Engineering\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_termsFile(termsFile):\n",
    "    termsFile = open(termsFile,\"r\")\n",
    "    terms = termsFile.readlines()\n",
    "    print('number of tech terms',len(terms))\n",
    "    keywords = [term.rstrip('\\n').lower() for term in terms]\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'terms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c400aff14253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmax_spaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmax_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'terms' is not defined"
     ]
    }
   ],
   "source": [
    "max_spaces = 0\n",
    "max_term = \"\"\n",
    "for term in terms:\n",
    "    count = 0\n",
    "    for tok in term:\n",
    "        if tok == ' ':\n",
    "            count+=1\n",
    "    if count > max_spaces:\n",
    "        max_spaces = count\n",
    "        max_term = term\n",
    "print('max spaces in a word in the termsFile',max_spaces)\n",
    "print('the word:', max_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_seniority(o_P):\n",
    "    seniority_levels = ['Internship','Entry level','Associate','Mid-Senior level','Director','Executive','Not Applicable']\n",
    "    s_tag = \"\"\n",
    "    s_boo =False\n",
    "    #Some weird inconsistency with linkedin seniority level upperlower caseness, edge case\n",
    "    if \"Seniority Level\" in o_P:\n",
    "        s_tag = \"Seniority Level\"\n",
    "        s_boo = True\n",
    "    elif \"Seniority level\" in o_P:\n",
    "        s_tag = \"Seniority level\"\n",
    "        s_boo = True\n",
    "    if s_boo:\n",
    "        seniorityIndex = o_P.index(s_tag) +1 \n",
    "        if o_P[seniorityIndex] in seniority_levels:\n",
    "            print('SENIORITY:', seniority_levels[seniority_levels.index(o_P[seniorityIndex])])\n",
    "\n",
    "def extract_degree_lvl(post):\n",
    "    deg_lvls = []\n",
    "    deg_lvl = {\n",
    "               'a':['associate\\'s','associate degree'],\n",
    "               'b':['ba','bs','bachelor','bachelor\\'s','b s'],\n",
    "               'm':['master','ms','master\\'s','m s'],\n",
    "               'p':['ph d','phd']\n",
    "\n",
    "    }\n",
    "    for d_key, d_value in deg_lvl.items():\n",
    "        for variation in d_value:\n",
    "            variation = \" \"+variation+\" \"\n",
    "            if variation in post:\n",
    "                deg_lvls.append(d_key)\n",
    "    print('EDUCATION LEVEL',set(deg_lvls))\n",
    "    \n",
    "def extract_degree_title(post):\n",
    "    deg_titles = []\n",
    "    deg_title = {'cs':['computer science','cs','c s'],\n",
    "                 'ce':['computer engineering','ce','c e'],\n",
    "                  'ee':['electrical engineering','ee','e e']\n",
    "\n",
    "    }\n",
    "\n",
    "    for d_key, d_value in deg_title.items():\n",
    "        for title in d_value:\n",
    "            title = \" \"+title+\" \"\n",
    "            if title in post:\n",
    "                deg_titles.append(d_key)\n",
    "       \n",
    "    print('DEGREE TITLE', set(deg_titles))\n",
    "\n",
    "def extract_tech_terms(post,keywords):\n",
    "    skills = []\n",
    "    for key in keywords:\n",
    "        key= \" \"+key+\" \"\n",
    "        if key in post:\n",
    "            skills.append(key.strip())\n",
    "    print('SKILLS',set(skills))\n",
    "    \n",
    "def extract_industry(o_P):\n",
    "    linkedin_industries = open(\"linkedin_industries.txt\",'r').read().split('\\n')\n",
    "    s_tag = \"\"\n",
    "    s_boo =False\n",
    "    industries = []\n",
    "    #Some weird inconsistency with inconsistency industry(ies) plural/singular, edge case\n",
    "    if \"Industry\" in o_P:\n",
    "        s_tag = \"Industry\"\n",
    "        s_boo = True\n",
    "    elif \"Industries\" in o_P:\n",
    "        s_tag = \"Industries\"\n",
    "        s_boo = True\n",
    "    if s_boo:\n",
    "        industryIndex = o_P.index(s_tag) +1 \n",
    "        for ind in linkedin_industries:\n",
    "            if ind in o_P[industryIndex] or ind.replace(\"&\",\"and\") in o_P[industryIndex]:\n",
    "                industries.append(ind)\n",
    "        print('INDUSTRIES:', industries)\n",
    "#def extract_yoe(post):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extraction(origPosts, jobPosts,keywords):    \n",
    "\n",
    "    for i in range(len(jobPosts)):           \n",
    "        o_P = origPosts[i].split('\\n')\n",
    "        #SENIORITY\n",
    "        extract_seniority(o_P)\n",
    "        #INDUSTRY\n",
    "        extract_industry(o_P)\n",
    "        #Keyword Extraction -----\n",
    "        #TECH SKILLS\n",
    "        extract_tech_terms(jobPosts[i], keywords)\n",
    "        #Degree level\n",
    "        extract_degree_lvl(jobPosts[i])\n",
    "        #DEGREE TITLE\n",
    "        extract_degree_title(jobPosts[i])\n",
    "        #YoE\n",
    "        \n",
    "        print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = {'4385545':{'skills':['javascript,python, angular'], \n",
    "                       'industry':['healthcare','telecommunication'],\n",
    "                       'education level':['bachelor','master'],\n",
    "                       'seniority':'Senior',\n",
    "                       'Years of Experience':['2-6 YOE'],\n",
    "                       'Degree Title':['ce','cs']\n",
    "                      },\n",
    "            '5345465':{\n",
    "                \n",
    "            }\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "number of tech terms 2174\n",
      "SENIORITY: Not Applicable\n",
      "INDUSTRIES: ['Information Technology and Services', 'Computer Software', 'Internet']\n",
      "SKILLS {'linux', 'less', 'web application', 'communication', 'product', 'mvc', 'java', 'framework', 'software development', 'information technology', 'javascript', 'testing', 'zoom', 'database'}\n",
      "EDUCATION LEVEL {'b'}\n",
      "DEGREE TITLE {'cs'}\n",
      "\n",
      "SENIORITY: Not Applicable\n",
      "INDUSTRIES: ['Information Technology and Services', 'Computer Software', 'Internet']\n",
      "SKILLS {'linux', 'less', 'web application', 'communication', 'product', 'mvc', 'java', 'framework', 'software development', 'information technology', 'javascript', 'testing', 'zoom', 'database'}\n",
      "EDUCATION LEVEL {'b'}\n",
      "DEGREE TITLE {'cs'}\n",
      "\n",
      "SKILLS {'jenkins', 'microservices', 'sql', 'next', 'growth', 'computer science', 'cpu', 'testing', 'bash', 'finance', 'devops', 'git', 'customer', 'performance testing', 'linux', 'communication', 'enterprise software', 'customer experience', 'api', 'spark', 'machine learning', 'python', 'kubernetes', 'airflow', 'security', 'nosql', 'hardware'}\n",
      "EDUCATION LEVEL {'p', 'b'}\n",
      "DEGREE TITLE {'cs'}\n",
      "\n",
      "SKILLS {'user', 'cassandra', 'pytorch', 'training', 'java', 'deployment', 'data science', 'kafka', 'spark', 'deep learning', 'tensorflow', 'hive', 'machine learning', 'python', 'go', 'product', 'c'}\n",
      "EDUCATION LEVEL {'p'}\n",
      "DEGREE TITLE set()\n",
      "\n",
      "SENIORITY: Internship\n",
      "INDUSTRIES: ['Internet']\n",
      "SKILLS {'prototype', 'pytorch', 'next', 'computer science', 'cpu', 'solid', 'c', 'user', 'computer architecture', 'deep learning', 'tensorflow', 'communication', 'optimization', 'training', 'framework', 'fpga', 'computer vision', 'image processing', 'machine learning', 'python', 'servers', 'debugging', 'https', 'convolutional neural network', 'hardware'}\n",
      "EDUCATION LEVEL {'p', 'm'}\n",
      "DEGREE TITLE {'ce', 'cs', 'ee'}\n",
      "\n",
      "SENIORITY: Not Applicable\n",
      "INDUSTRIES: ['Computer Software', 'Marketing & Advertising', 'Internet']\n",
      "SKILLS {'jenkins', 'cassandra', 'aws', 'sql', 'rest', 'json', 'computer science', 'javascript', 'testing', 'c', 'infrastructure', 'it management', 'agile', 'svn', 'mockito', 'xml', 'git', 'grpc', 'kafka', 'analysis', 'customer', 'data mining', 'kotlin', 'mapreduce', 'redis', 'nosql databases', 'cocoa', 'docker', 'less', 'junit', 'communication', 'css', 'training', 'security', 'software development', 'api', 'kanban', 'information technology', 'scrum', 'gradle', 'kubernetes', 'product', 'jira', 'availability', 'unit testing', 'html', 'java', 'jvm', 'design patterns', 'scalability', 'maven', 'nosql'}\n",
      "EDUCATION LEVEL {'p', 'b', 'm'}\n",
      "DEGREE TITLE {'ce', 'cs'}\n",
      "\n",
      "SKILLS {'dynamodb', 'digital marketing', 'algorithm', 'redux', 'ruby', 'computer science', 'testing', 'solid', 'infrastructure', 'ruby on rails', 'lift', 'mysql', 'agile', 'problem solving', 'mentorship', 'web services', 'ux', 'nosql databases', 'less', 'communication', 'optimization', 'typescript', 'framework', 'deployment', 'software development', 'api', 'saas', 'postgresql', 'product', 'serverless framework', 'switch', 'scope', 'ui', 'nosql', 'database'}\n",
      "EDUCATION LEVEL {'b'}\n",
      "DEGREE TITLE {'cs'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orig_posts, jobPosts = preprocessing(\"sample_jobposts.txt\")\n",
    "keywords = read_termsFile(\"final_keywords.txt\")\n",
    "data_extraction(orig_posts, jobPosts, keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'computer', 'science', 'or', 'equivalent'] 5 ['years', 'of', 'industry', 'experience']\n",
      "['and', 'national', 'businesses', 'in', 'over'] 4 ['000', 'cities', 'and', 'all']\n",
      "['national', 'businesses', 'in', 'over', '4'] 000 ['cities', 'and', 'all', '50']\n",
      "['4', '000', 'cities', 'and', 'all'] 50 ['states', 'across', 'the', 'united']\n",
      "['states', 'and', 'canada', 'founded', 'in'] 2013 ['doordash', 'empowers', 'merchants', 'to']\n",
      "['staffing', 'and', 'recruiting', 'software', 'engineer'] 10 ['positions', 'google', 'llc', 'mountain']\n",
      "['research', 'proj', 'internship', 'thesis', 'or'] 1 ['year', 'exp', 'in', 'c']\n",
      "['or', 'exp', 'is', 'acceptable', 'salary'] 150 ['000', '240', '000', 'sched']\n",
      "['exp', 'is', 'acceptable', 'salary', '150'] 000 ['240', '000', 'sched', 'm']\n",
      "['is', 'acceptable', 'salary', '150', '000'] 240 ['000', 'sched', 'm', 'f']\n",
      "['acceptable', 'salary', '150', '000', '240'] 000 ['sched', 'm', 'f', '9am']\n",
      "['ref', 'goo98691', 'p', 'o', 'box'] 56625 ['atlanta', 'ga', '30343', 'show']\n",
      "['o', 'box', '56625', 'atlanta', 'ga'] 30343 ['show', 'less', 'seniority', 'level']\n"
     ]
    }
   ],
   "source": [
    "tokenize = jobPosts[5].split(' ')\n",
    "for w in range(len(tokenize)):\n",
    "    if tokenize[w].isdigit():\n",
    "        print(tokenize[w-5:w],tokenize[w],tokenize[w+1:w+5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_in = scraped_in.split('\\t')\n",
    "for s in range(len(scraped_in)):\n",
    "    scraped_in[s] = scraped_in[s].replace(\"\\n\",\"\")\n",
    "    scraped_in[s] = ''.join([i for i in scraped_in[s] if not i.isdigit()])\n",
    "scraped_in[0] = \"Information Technology and Services\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_in = scraped_in[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Marketing and Advertising'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Marketing & Advertising\".replace(\"&\",\"and\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
