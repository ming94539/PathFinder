{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problems Encountered\n",
    "'''\n",
    "1. Abbreviation - B.A. B.S. - after my punctuation remover, it becomes B A B S. Making it miss stuff\n",
    "2. Tokenization - Miss key words with two or more words like \"React Native\"\n",
    "3. Double spaces - not completely sure yet but I think it's from the punctuation remover, but \n",
    "the regex that removes multiple consecutive spaces can deal with that\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n"
     ]
    }
   ],
   "source": [
    "#Seperate Job Posts, put them all in a list, with each element a job post\n",
    "jobsFile = open(\"sample_jobposts.txt\")\n",
    "jobslines = jobsFile.readlines()\n",
    "origPosts = []\n",
    "jobPosts = []\n",
    "post = \"\"\n",
    "origPost = \"\"\n",
    "firstOne = True\n",
    "for l in range(len(jobslines)):\n",
    "    if jobslines[l] == \"BREAK\\n\" or l == len(jobslines)-1 :\n",
    "        if firstOne:\n",
    "            firstOne = False\n",
    "        else:\n",
    "            jobPosts.append(post)\n",
    "            origPosts.append(origPost)\n",
    "            post = \"\"\n",
    "            origPost = \"\"\n",
    "        continue\n",
    "    origPost += jobslines[l]\n",
    "   # post += jobslines[l].replaceAll(\"[\\\\p{Punct}&&[^.]]\", \"\").lower();\n",
    "    post+= re.sub(r'[^\\w\\s]', ' ', jobslines[l].lower())\n",
    "    \n",
    "print('----')\n",
    "for p in range(len(jobPosts)):\n",
    "    jobPosts[p]= re.sub(' +', ' ', jobPosts[p].replace('\\n',' ')) #remove unnecessary double/triple white space\n",
    "#print(jobPosts[2])\n",
    "# for pos in range(len(jobPosts)):\n",
    "#     jobPosts[pos]= jobPosts[pos].strip(\"\\n\") \n",
    "#     print(jobPosts[pos])\n",
    "#strip after getting the posts, since break\\n relies on \\n\n",
    "#Can't use tokenization because some keywords contain multiple words, can't match individually\n",
    "#lowercase for consistency\n",
    "#strip \"\\n\" since some words are connected to it like \"\\njava\", which won't let us detect java\n",
    "# for p in range(len(jobPosts)):\n",
    "#     jobPosts[p] = word_tokenize(jobPosts[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kuaishou is the leading short video and photo sharing app in china where our mission is to provide users with a personal space to share moments from their lives with over 700 million audience and more than 200 million active daily users kwai provides an almost limitless look at everyday slices of life that unfolds in real time viewers can explore a rich array of glimpses into fitness homes cooking health and wellness fashion and other interests kuaishou is a user oriented technology driven company which uses cutting edge machine learning techniques for instantly curated presentations and develops new ai algorithms and technologies to solve challenging industrial problems you may visit https usrdc kuaishou com to learn more about us about the position we are an applied research and engineering team responsible for developing advanced ai technologies and hardware platforms for efficient inferences on cloud servers or edge devices across kuaishou products we are looking for deep learning software interns at our palo alto office to develop exciting technologies for kuaishou s next generation products job responsibilities develop and prototype new deep learning models and training algorithms for speech recognition computer vision and natural language processing train deep learning models on computing clusters to perform audio and visual recognition tasks analyze and optimize deep neural algorithms and associated pre post processing code including not limit to model compresion quantization and acceleration develop fixed point implementation of common operators in tensorflow or pytorch minimum qualifications master or phd in computer engineering computer science and electrical engineering or other related fields familiar with basic deep learning concepts including convolutional neural network and recurrent neural network proficiency in at least one major machine learning framework such as tensorflow and pytorch hands on programming and debugging experience in c c or python creativity and curiosity for solving highly complex problems excellent communication and collaboration skills preferred qualifications solid mathematical background especially in optimization theory random process and linear algebra knowledge in neural network optimization techniques such as quantization compression pruning and layer fusion basic understanding of computer architecture and computing platforms such as cpu gpu fpga or dsp familiar with neural network image processing and video compression applicant rank top 50 of 159 applicants contact the job poster job poster profile meiqi wu 快手 hr 招聘 send inmail job details seniority level internship industry internet employment type internship job functions \n"
     ]
    }
   ],
   "source": [
    "print(jobPosts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-415abd5ede9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjobPosts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'master'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mjobPosts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "temp = jobPosts[0].find('master')\n",
    "#print(temp)\n",
    "#jobPosts[0][temp-15:temp+15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2173\n"
     ]
    }
   ],
   "source": [
    "termsFile = open(\"final_keywords.txt\",\"r\")\n",
    "terms = termsFile.readlines()\n",
    "print(len(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kafka\\n'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms[2172]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2170\n",
      "max spaces in a word in the termsFile 5\n",
      "the word: load, stress and performance testing tools\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_spaces = 0\n",
    "max_term = \"\"\n",
    "for term in terms:\n",
    "    count = 0\n",
    "    for tok in term:\n",
    "        if tok == ' ':\n",
    "            count+=1\n",
    "    if count > max_spaces:\n",
    "        max_spaces = count\n",
    "        max_term = term\n",
    "print('max spaces in a word in the termsFile',max_spaces)\n",
    "print('the word:', max_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [term.rstrip('\\n').lower() for term in terms]\n",
    "deg_lvl = {\n",
    "           'a':['associate\\'s','associate degree'],\n",
    "           'b':['ba','bs','bachelor','bachelor\\'s','b s'],\n",
    "           'm':['master','ms','master\\'s','m s'],\n",
    "           'p':['ph d','phd']\n",
    "    \n",
    "}\n",
    "deg_title = {'cs':['computer science','cs','c s'],\n",
    "             'ce':['computer engineering','ce','c e'],\n",
    "              'ee':['electrical engineering','ee','e e']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKILLS ['javascript', 'less', 'java', 'database', 'testing', 'linux', 'product', 'communication', 'mvc', 'web application', 'zoom', 'software development', 'framework', 'information technology']\n",
      "Education level ['b']\n",
      "Degree title ['cs']\n",
      "\n",
      "SKILLS ['javascript', 'less', 'java', 'database', 'testing', 'linux', 'product', 'communication', 'mvc', 'web application', 'zoom', 'software development', 'framework', 'information technology']\n",
      "Education level ['b']\n",
      "Degree title ['cs']\n",
      "\n",
      "SKILLS ['next', 'python', 'nosql', 'sql', 'performance testing', 'testing', 'bash', 'cpu', 'devops', 'kubernetes', 'linux', 'customer', 'growth', 'communication', 'api', 'microservices', 'security', 'airflow', 'machine learning', 'git', 'jenkins', 'finance', 'computer science', 'customer experience', 'enterprise software', 'hardware', 'spark']\n",
      "Education level ['b', 'p']\n",
      "Degree title ['cs']\n",
      "\n",
      "SKILLS ['java', 'python', 'go', 'cassandra', 'deployment', 'product', 'user', 'training', 'pytorch', 'tensorflow', 'machine learning', 'data science', 'deep learning', 'spark', 'hive', 'kafka']\n",
      "Education level ['p']\n",
      "Degree title []\n",
      "\n",
      "SKILLS ['prototype', 'next', 'python', 'cpu', 'https', 'servers', 'user', 'communication', 'training', 'solid', 'computer vision', 'convolutional neural network', 'pytorch', 'image processing', 'tensorflow', 'optimization', 'machine learning', 'deep learning', 'debugging', 'computer architecture', 'computer science', 'fpga', 'framework', 'hardware']\n",
      "Education level ['m', 'p']\n",
      "Degree title ['cs', 'ce', 'ee']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(jobPosts)):\n",
    "    skills = []\n",
    "    deg_titles = []\n",
    "    deg_lvls = []\n",
    "    for key in keywords:\n",
    "        key= \" \"+key+\" \"\n",
    "        if key in jobPosts[i]:\n",
    "            skills.append(key.strip())\n",
    "    print('SKILLS',skills)\n",
    "    for d_key, d_value in deg_lvl.items():\n",
    "        for variation in d_value:\n",
    "            variation = \" \"+variation+\" \"\n",
    "            if variation in jobPosts[i]:\n",
    "                deg_lvls.append(d_key)\n",
    "    \n",
    "    for d_key, d_value in deg_title.items():\n",
    "        for title in d_value:\n",
    "            title = \" \"+title+\" \"\n",
    "            if title in jobPosts[i]:\n",
    "                deg_titles.append(d_key)\n",
    "    print('Education level',deg_lvls)\n",
    "    print('Degree title', deg_titles)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = {'4385545':{'skills':['javascript,python, angular'], \n",
    "                       'industry':['healthcare','telecommunication'],\n",
    "                       'education':['bachelor','master'],\n",
    "                       'seniority':'Senior',\n",
    "                       'Part of Stack': ['front end','backend'],\n",
    "                       'Experience':['2-6 YOE'],\n",
    "                       'preferred qualification':['React','PhD'],\n",
    "                      },\n",
    "            '5345465':{\n",
    "                \n",
    "            }\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
